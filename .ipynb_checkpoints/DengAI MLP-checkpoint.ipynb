{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import datetime\n",
    "import math\n",
    "from sklearn import datasets\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_features = pd.read_csv('dengue_features_train.csv',\n",
    "                             index_col=[0,1,2])\n",
    "train_labels = pd.read_csv('dengue_labels_train.csv',\n",
    "                          index_col=[0,1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42\n",
    "tf.set_random_seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_weights(shape):\n",
    "\n",
    "    \"\"\" Weight initialization \"\"\"\n",
    "\n",
    "    weights = tf.random_normal(shape, stddev=0.1)\n",
    "\n",
    "    return tf.Variable(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def forwardprop(X, w_1, w_2, w_3):\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    Forward-propagation.\n",
    "\n",
    "    IMPORTANT: yhat is not softmax since TensorFlow's softmax_cross_entropy_with_logits() does that internally.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    h    = tf.nn.sigmoid(tf.matmul(X, w_1))  # The \\sigma function\n",
    "    h2    = tf.nn.sigmoid(tf.matmul(h, w_2))\n",
    "\n",
    "    yhat = tf.matmul(h2, w_3)  # The \\varphi function\n",
    "\n",
    "    return yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data, labels):\n",
    "    \n",
    "    df = data\n",
    "    \n",
    "    # select features we want\n",
    "    features = ['reanalysis_specific_humidity_g_per_kg', \n",
    "                 'reanalysis_dew_point_temp_k', \n",
    "                 'station_avg_temp_c', \n",
    "                 'station_min_temp_c']\n",
    "    df = df[features]\n",
    "    \n",
    "    # fill missing values\n",
    "    df.fillna(method='ffill', inplace=True)\n",
    "\n",
    "\n",
    "    dfl = labels\n",
    "    \n",
    "    \n",
    "    # separate san juan and iquitos\n",
    "    sjfeats = df.loc['sj']\n",
    "    iqfeats = df.loc['iq']\n",
    "    \n",
    "    sjlabs = dfl.loc['sj']\n",
    "    iqlabs = dfl.loc['iq']\n",
    "\n",
    "    # Prepend the column of 1s for bias\n",
    "    sjN, sjM  = sjfeats.shape\n",
    "    sjall_X = np.ones((sjN, sjM + 1))\n",
    "    sjall_X[:, 1:] = sjfeats\n",
    "    \n",
    "    iqN, iqM  = iqfeats.shape\n",
    "    iqall_X = np.ones((iqN, iqM + 1))\n",
    "    iqall_X[:, 1:] = iqfeats\n",
    "    \n",
    "    sjlabs = sjlabs.as_matrix()\n",
    "    \n",
    "    return sjall_X, iqall_X, sjlabs, iqlabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/griffin/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py:2852: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  downcast=downcast, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "sj_train, iq_train, sj_target, iq_target = preprocess_data(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [260, 936]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-104-b9fe3725f2c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m sjx_train, sjx_test, sjy_train, sjy_test = train_test_split(sj_train, sj_target, \n\u001b[0;32m----> 2\u001b[0;31m                                                                     test_size=0.2, random_state=42)\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m iqx_train, iqx_test, iqy_train, iqy_test = train_test_split(iq_train, iq_target, \n\u001b[1;32m      5\u001b[0m                                                                     test_size=0.2, random_state=42)\n",
      "\u001b[0;32m/home/griffin/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(*arrays, **options)\u001b[0m\n\u001b[1;32m   1687\u001b[0m         \u001b[0mtest_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.25\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1689\u001b[0;31m     \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstratify\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/griffin/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mindexable\u001b[0;34m(*iterables)\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/griffin/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 181\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [260, 936]"
     ]
    }
   ],
   "source": [
    "sjx_train, sjx_test, sjy_train, sjy_test = train_test_split(sj_train, sj_target, \n",
    "                                                                    test_size=0.2, random_state=42)\n",
    "\n",
    "iqx_train, iqx_test, iqy_train, iqy_test = train_test_split(iq_train, iq_target, \n",
    "                                                                    test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sj_x_size = sjx_train.shape[1]\n",
    "\n",
    "iq_x_size = iqx_train.shape[1]             \n",
    "\n",
    "y_size = 1\n",
    "h_size = 256               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sj_X = tf.placeholder(\"float\", shape=[None, sj_x_size])\n",
    "iq_X = tf.placeholder(\"float\", shape=[None, iq_x_size])\n",
    "y = tf.placeholder(\"float\", shape=[None, y_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sj_w_1 = init_weights((sj_x_size, h_size))\n",
    "iq_w_1 = init_weights((iq_x_size, h_size))\n",
    "w_2 = init_weights((h_size, h_size))\n",
    "w_3 = init_weights((h_size, y_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sj_yhat = forwardprop(sj_X, sj_w_1, w_2, w_3)\n",
    "sj_predict = tf.to_int64(sj_yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iq_yhat = forwardprop(iq_X, iq_w_1, w_2, w_3)\n",
    "iq_predict = tf.to_int64(iq_yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sj_cost    = tf.losses.mean_squared_error(labels=y, predictions=sj_yhat)\n",
    "sj_updates = tf.train.GradientDescentOptimizer(0.0000001).minimize(sj_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iq_cost    = tf.losses.mean_squared_error(labels=y, predictions=iq_yhat)\n",
    "iq_updates = tf.train.GradientDescentOptimizer(0.0000001).minimize(iq_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 1, train loss = 31.45, test loss = 30.74\n",
      "Epoch = 11, train loss = 28.41, test loss = 27.85\n",
      "Epoch = 21, train loss = 26.36, test loss = 25.95\n",
      "Epoch = 31, train loss = 25.35, test loss = 25.10\n",
      "Epoch = 41, train loss = 24.78, test loss = 24.78\n",
      "Epoch = 51, train loss = 24.68, test loss = 24.95\n",
      "Epoch = 61, train loss = 24.80, test loss = 25.24\n",
      "Epoch = 71, train loss = 25.05, test loss = 25.67\n",
      "Epoch = 81, train loss = 25.42, test loss = 26.18\n",
      "Epoch = 91, train loss = 25.91, test loss = 26.78\n",
      "Epoch = 100, train loss = 26.20, test loss = 27.12\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "        # Train with each example\n",
    "        for i in range(len(sjx_train)):\n",
    "            sess.run(sj_updates, feed_dict={sj_X: sjx_train[i: i + 1], y: sjy_train[i: i + 1]})\n",
    "\n",
    "        sj_train_accuracy = metrics.mean_absolute_error(sjy_train,\n",
    "                                 sess.run(sj_predict, feed_dict={sj_X: sjx_train}))\n",
    "        sj_test_accuracy  = metrics.mean_absolute_error(sjy_test,\n",
    "                                 sess.run(sj_predict, feed_dict={sj_X: sjx_test}))\n",
    "\n",
    "        if epoch % 10 == 0 or epoch == epochs-1:\n",
    "            print(\"Epoch = %d, train loss = %.2f, test loss = %.2f\"\n",
    "                  % (epoch + 1, sj_train_accuracy, sj_test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 1, train loss = 17.40, test loss = 17.62\n",
      "Epoch = 11, train loss = 15.74, test loss = 15.89\n",
      "Epoch = 21, train loss = 14.94, test loss = 15.05\n",
      "Epoch = 31, train loss = 13.36, test loss = 13.39\n",
      "Epoch = 41, train loss = 12.60, test loss = 12.62\n",
      "Epoch = 51, train loss = 11.85, test loss = 11.86\n",
      "Epoch = 61, train loss = 11.14, test loss = 11.09\n",
      "Epoch = 71, train loss = 11.14, test loss = 11.09\n",
      "Epoch = 81, train loss = 10.44, test loss = 10.32\n",
      "Epoch = 91, train loss = 9.75, test loss = 9.55\n",
      "Epoch = 100, train loss = 9.75, test loss = 9.55\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "        # Train with each example\n",
    "        for i in range(len(iqx_train)):\n",
    "            sess.run(iq_updates, feed_dict={iq_X: iqx_train[i: i + 1], y: iqy_train[i: i + 1]})\n",
    "\n",
    "        iq_train_accuracy = metrics.mean_absolute_error(iqy_train,\n",
    "                                 sess.run(iq_predict, feed_dict={iq_X: iqx_train}))\n",
    "        iq_test_accuracy  = metrics.mean_absolute_error(iqy_test,\n",
    "                                 sess.run(iq_predict, feed_dict={iq_X: iqx_test}))\n",
    "\n",
    "        if epoch % 10 == 0 or epoch == epochs-1:\n",
    "            print(\"Epoch = %d, train loss = %.2f, test loss = %.2f\"\n",
    "                  % (epoch + 1, iq_train_accuracy, iq_test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_features = pd.read_csv('dengue_features_test.csv',\n",
    "                             index_col=[0,1,2])\n",
    "\n",
    "def preprocess_data_test(data):\n",
    "    \n",
    "    df = data\n",
    "    \n",
    "    # select features we want\n",
    "    features = ['reanalysis_specific_humidity_g_per_kg', 'reanalysis_dew_point_temp_k',\n",
    "                'station_avg_temp_c', 'station_min_temp_c',\n",
    "                'reanalysis_precip_amt_kg_per_m2', 'reanalysis_relative_humidity_percent', \n",
    "                'reanalysis_sat_precip_amt_mm']\n",
    "    df = df[features]\n",
    "    \n",
    "    # fill missing values\n",
    "    df.fillna(method='ffill', inplace=True)\n",
    "\n",
    "    \n",
    "    # separate san juan and iquitos\n",
    "    sjfeats = df.loc['sj']\n",
    "    iqfeats = df.loc['iq']\n",
    "\n",
    "\n",
    "    # Prepend the column of 1s for bias\n",
    "    sjN, sjM  = sjfeats.shape\n",
    "    sjall_X = np.ones((sjN, sjM + 1))\n",
    "    sjall_X[:, 1:] = sjfeats\n",
    "    \n",
    "    iqN, iqM  = iqfeats.shape\n",
    "    iqall_X = np.ones((iqN, iqM + 1))\n",
    "    iqall_X[:, 1:] = iqfeats\n",
    "    \n",
    "    return sjall_X, iqall_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/griffin/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py:2852: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  downcast=downcast, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "sj_test, iq_test = preprocess_data_test(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_predict_sj = sess.run(sj_predict, feed_dict={sj_X: sj_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_predict_iq = sess.run(iq_predict, feed_dict={iq_X: iq_test})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission = pd.read_csv(\"submission_format.csv\",\n",
    "                         index_col=[0, 1, 2])\n",
    "\n",
    "submission.total_cases = np.concatenate([final_predict_sj, final_predict_iq])\n",
    "submission.to_csv(\"submission_MLP.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of                       total_cases\n",
       "city year weekofyear             \n",
       "sj   2008 18                   21\n",
       "          19                   21\n",
       "          20                   21\n",
       "          21                   21\n",
       "          22                   21\n",
       "          23                   21\n",
       "          24                   21\n",
       "          25                   21\n",
       "          26                   21\n",
       "          27                   21\n",
       "          28                   21\n",
       "          29                   21\n",
       "          30                   21\n",
       "          31                   21\n",
       "          32                   21\n",
       "          33                   21\n",
       "          34                   21\n",
       "          35                   21\n",
       "          36                   21\n",
       "          37                   21\n",
       "          38                   21\n",
       "          39                   21\n",
       "          40                   21\n",
       "          41                   21\n",
       "          42                   21\n",
       "          43                   21\n",
       "          44                   21\n",
       "          45                   21\n",
       "          46                   21\n",
       "          47                   21\n",
       "...                           ...\n",
       "iq   2012 48                   13\n",
       "          49                   13\n",
       "          50                   13\n",
       "          51                   13\n",
       "     2013 1                    13\n",
       "          2                    13\n",
       "          3                    13\n",
       "          4                    13\n",
       "          5                    13\n",
       "          6                    13\n",
       "          7                    13\n",
       "          8                    13\n",
       "          9                    13\n",
       "          10                   13\n",
       "          11                   13\n",
       "          12                   13\n",
       "          13                   13\n",
       "          14                   13\n",
       "          15                   13\n",
       "          16                   13\n",
       "          17                   13\n",
       "          18                   13\n",
       "          19                   13\n",
       "          20                   13\n",
       "          21                   13\n",
       "          22                   13\n",
       "          23                   13\n",
       "          24                   13\n",
       "          25                   13\n",
       "          26                   13\n",
       "\n",
       "[416 rows x 1 columns]>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
