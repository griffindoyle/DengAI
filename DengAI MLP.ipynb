{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import datetime\n",
    "import math\n",
    "from sklearn import datasets\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_features = pd.read_csv('dengue_features_train.csv',\n",
    "                             index_col=[0,1,2])\n",
    "train_labels = pd.read_csv('dengue_labels_train.csv',\n",
    "                          index_col=[0,1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42\n",
    "tf.set_random_seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_weights(shape):\n",
    "\n",
    "    \"\"\" Weight initialization \"\"\"\n",
    "\n",
    "    weights = tf.random_normal(shape, stddev=0.1)\n",
    "\n",
    "    return tf.Variable(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def forwardprop(X, w_1, w_2, w_3):\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    Forward-propagation.\n",
    "\n",
    "    IMPORTANT: yhat is not softmax since TensorFlow's softmax_cross_entropy_with_logits() does that internally.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    h    = tf.nn.relu(tf.matmul(X, w_1))  # The \\sigma function\n",
    "    h2    = tf.nn.relu(tf.matmul(h, w_2))\n",
    "\n",
    "    yhat = tf.matmul(h2, w_3)  # The \\varphi function\n",
    "\n",
    "    return yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_data(data, labels):\n",
    "    \n",
    "    df = data\n",
    "    \n",
    "    # select features we want\n",
    "    features = ['reanalysis_specific_humidity_g_per_kg', \n",
    "                 'reanalysis_dew_point_temp_k', \n",
    "                 'station_avg_temp_c', \n",
    "                 'station_min_temp_c']\n",
    "    df = df[features]\n",
    "    \n",
    "    # fill missing values\n",
    "    df.fillna(method='ffill', inplace=True)\n",
    "\n",
    "\n",
    "    dfl = labels\n",
    "    \n",
    "    \n",
    "    # separate san juan and iquitos\n",
    "    sjfeats = df.loc['sj']\n",
    "    iqfeats = df.loc['iq']\n",
    "    \n",
    "    sjlabs = dfl.loc['sj']\n",
    "    iqlabs = dfl.loc['iq']\n",
    "\n",
    "    # Prepend the column of 1s for bias\n",
    "    sjN, sjM  = sjfeats.shape\n",
    "    sjall_X = np.ones((sjN, sjM + 1))\n",
    "    sjall_X[:, 1:] = sjfeats\n",
    "    \n",
    "    iqN, iqM  = iqfeats.shape\n",
    "    iqall_X = np.ones((iqN, iqM + 1))\n",
    "    iqall_X[:, 1:] = iqfeats\n",
    "    \n",
    "    sjlabs = sjlabs.as_matrix()\n",
    "    \n",
    "    return sjall_X, iqall_X, sjlabs, iqlabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/griffin/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py:2852: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  downcast=downcast, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "sj_train, iq_train, sj_target, iq_target = preprocess_data(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sjx_train, sjx_test, sjy_train, sjy_test = train_test_split(sj_train, sj_target, \n",
    "                                                                    test_size=0.2, random_state=42)\n",
    "\n",
    "iqx_train, iqx_test, iqy_train, iqy_test = train_test_split(iq_train, iq_target, \n",
    "                                                                    test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sj_x_size = sjx_train.shape[1]\n",
    "\n",
    "iq_x_size = iqx_train.shape[1]             \n",
    "\n",
    "y_size = 1\n",
    "h_size = 256               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sj_X = tf.placeholder(\"float\", shape=[None, sj_x_size])\n",
    "iq_X = tf.placeholder(\"float\", shape=[None, iq_x_size])\n",
    "y = tf.placeholder(\"float\", shape=[None, y_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sj_w_1 = init_weights((sj_x_size, h_size))\n",
    "iq_w_1 = init_weights((iq_x_size, h_size))\n",
    "w_2 = init_weights((h_size, h_size))\n",
    "w_3 = init_weights((h_size, y_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sj_yhat = forwardprop(sj_X, sj_w_1, w_2, w_3)\n",
    "sj_predict = tf.to_int64(sj_yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iq_yhat = forwardprop(iq_X, iq_w_1, w_2, w_3)\n",
    "iq_predict = tf.to_int64(iq_yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sj_cost    = tf.losses.mean_squared_error(labels=y, predictions=sj_yhat)\n",
    "sj_updates = tf.train.GradientDescentOptimizer(0.0000001).minimize(sj_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iq_cost    = tf.losses.mean_squared_error(labels=y, predictions=iq_yhat)\n",
    "iq_updates = tf.train.GradientDescentOptimizer(0.0000001).minimize(iq_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 1, train loss = 27.54, test loss = 28.53\n",
      "Epoch = 11, train loss = 26.79, test loss = 27.74\n",
      "Epoch = 21, train loss = 26.43, test loss = 27.38\n",
      "Epoch = 31, train loss = 26.20, test loss = 27.16\n",
      "Epoch = 41, train loss = 26.14, test loss = 27.05\n",
      "Epoch = 51, train loss = 26.08, test loss = 27.04\n",
      "Epoch = 61, train loss = 26.05, test loss = 26.99\n",
      "Epoch = 71, train loss = 26.04, test loss = 27.01\n",
      "Epoch = 81, train loss = 26.03, test loss = 26.98\n",
      "Epoch = 91, train loss = 26.00, test loss = 26.96\n",
      "Epoch = 100, train loss = 26.03, test loss = 26.95\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "for epoch in range(epochs):\n",
    "        # Train with each example\n",
    "        for i in range(len(sjx_train)):\n",
    "            sess.run(sj_updates, feed_dict={sj_X: sjx_train[i: i + 1], y: sjy_train[i: i + 1]})\n",
    "\n",
    "        sj_train_accuracy = metrics.mean_absolute_error(sjy_train,\n",
    "                                 sess.run(sj_predict, feed_dict={sj_X: sjx_train}))\n",
    "        sj_test_accuracy  = metrics.mean_absolute_error(sjy_test,\n",
    "                                 sess.run(sj_predict, feed_dict={sj_X: sjx_test}))\n",
    "\n",
    "        if epoch % 10 == 0 or epoch == epochs-1:\n",
    "            print(\"Epoch = %d, train loss = %.2f, test loss = %.2f\"\n",
    "                  % (epoch + 1, sj_train_accuracy, sj_test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch = 1, train loss = 6.36, test loss = 5.75\n",
      "Epoch = 11, train loss = 6.34, test loss = 5.77\n",
      "Epoch = 21, train loss = 6.33, test loss = 5.78\n",
      "Epoch = 31, train loss = 6.33, test loss = 5.79\n",
      "Epoch = 41, train loss = 6.32, test loss = 5.78\n",
      "Epoch = 51, train loss = 6.31, test loss = 5.79\n",
      "Epoch = 61, train loss = 6.31, test loss = 5.81\n",
      "Epoch = 71, train loss = 6.30, test loss = 5.79\n",
      "Epoch = 81, train loss = 6.29, test loss = 5.77\n",
      "Epoch = 91, train loss = 6.29, test loss = 5.77\n",
      "Epoch = 100, train loss = 6.29, test loss = 5.77\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "        # Train with each example\n",
    "        for i in range(len(iqx_train)):\n",
    "            sess.run(iq_updates, feed_dict={iq_X: iqx_train[i: i + 1], y: iqy_train[i: i + 1]})\n",
    "\n",
    "        iq_train_accuracy = metrics.mean_absolute_error(iqy_train,\n",
    "                                 sess.run(iq_predict, feed_dict={iq_X: iqx_train}))\n",
    "        iq_test_accuracy  = metrics.mean_absolute_error(iqy_test,\n",
    "                                 sess.run(iq_predict, feed_dict={iq_X: iqx_test}))\n",
    "\n",
    "        if epoch % 10 == 0 or epoch == epochs-1:\n",
    "            print(\"Epoch = %d, train loss = %.2f, test loss = %.2f\"\n",
    "                  % (epoch + 1, iq_train_accuracy, iq_test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_features = pd.read_csv('dengue_features_test.csv',\n",
    "                             index_col=[0,1,2])\n",
    "\n",
    "def preprocess_data_test(data):\n",
    "    \n",
    "    df = data\n",
    "    \n",
    "    # select features we want\n",
    "    features = ['reanalysis_specific_humidity_g_per_kg', \n",
    "                'reanalysis_dew_point_temp_k',\n",
    "                'station_avg_temp_c', \n",
    "                'station_min_temp_c']\n",
    "    df = df[features]\n",
    "    \n",
    "    # fill missing values\n",
    "    df.fillna(method='ffill', inplace=True)\n",
    "\n",
    "    \n",
    "    # separate san juan and iquitos\n",
    "    sjfeats = df.loc['sj']\n",
    "    iqfeats = df.loc['iq']\n",
    "\n",
    "\n",
    "    # Prepend the column of 1s for bias\n",
    "    sjN, sjM  = sjfeats.shape\n",
    "    sjall_X = np.ones((sjN, sjM + 1))\n",
    "    sjall_X[:, 1:] = sjfeats\n",
    "    \n",
    "    iqN, iqM  = iqfeats.shape\n",
    "    iqall_X = np.ones((iqN, iqM + 1))\n",
    "    iqall_X[:, 1:] = iqfeats\n",
    "    \n",
    "    return sjall_X, iqall_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/griffin/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py:2852: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  downcast=downcast, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "sj_test, iq_test = preprocess_data_test(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_predict_sj = sess.run(sj_predict, feed_dict={sj_X: sj_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_predict_iq = sess.run(iq_predict, feed_dict={iq_X: iq_test})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission = pd.read_csv(\"submission_format.csv\",\n",
    "                         index_col=[0, 1, 2])\n",
    "\n",
    "submission.total_cases = np.concatenate([final_predict_sj, final_predict_iq])\n",
    "submission.to_csv(\"submission_MLP.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of                       total_cases\n",
       "city year weekofyear             \n",
       "sj   2008 18                   29\n",
       "          19                   29\n",
       "          20                   31\n",
       "          21                   31\n",
       "          22                   31\n",
       "          23                   32\n",
       "          24                   31\n",
       "          25                   32\n",
       "          26                   32\n",
       "          27                   32\n",
       "          28                   31\n",
       "          29                   33\n",
       "          30                   32\n",
       "          31                   33\n",
       "          32                   32\n",
       "          33                   33\n",
       "          34                   33\n",
       "          35                   33\n",
       "          36                   33\n",
       "          37                   32\n",
       "          38                   32\n",
       "          39                   31\n",
       "          40                   31\n",
       "          41                   32\n",
       "          42                   31\n",
       "          43                   31\n",
       "          44                   31\n",
       "          45                   32\n",
       "          46                   31\n",
       "          47                   31\n",
       "...                           ...\n",
       "iq   2012 48                    7\n",
       "          49                    7\n",
       "          50                    6\n",
       "          51                    7\n",
       "     2013 1                     7\n",
       "          2                     6\n",
       "          3                     7\n",
       "          4                     7\n",
       "          5                     7\n",
       "          6                     7\n",
       "          7                     7\n",
       "          8                     7\n",
       "          9                     7\n",
       "          10                    7\n",
       "          11                    7\n",
       "          12                    7\n",
       "          13                    7\n",
       "          14                    7\n",
       "          15                    7\n",
       "          16                    7\n",
       "          17                    6\n",
       "          18                    5\n",
       "          19                    7\n",
       "          20                    6\n",
       "          21                    7\n",
       "          22                    7\n",
       "          23                    6\n",
       "          24                    6\n",
       "          25                    6\n",
       "          26                    7\n",
       "\n",
       "[416 rows x 1 columns]>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
