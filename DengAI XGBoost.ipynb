{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/griffin/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import time\n",
    "import datetime\n",
    "import math\n",
    "from sklearn import datasets\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.feature_selection import SelectFromModel, VarianceThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_features = pd.read_csv('dengue_features_train.csv',\n",
    "                             index_col=[0,1,2])\n",
    "train_labels = pd.read_csv('dengue_labels_train.csv',\n",
    "                          index_col=[0,1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42\n",
    "tf.set_random_seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_data(data, labels):\n",
    "    \n",
    "    df = data\n",
    "    \n",
    "    # fill missing values\n",
    "    df.fillna(method='ffill', inplace=True)\n",
    "    \n",
    "    df = df.drop(['week_start_date'],axis=1)\n",
    "\n",
    "    dfl = labels\n",
    "    \n",
    "    \n",
    "    # separate san juan and iquitos\n",
    "    sjfeats = df.loc['sj']\n",
    "    iqfeats = df.loc['iq']\n",
    "    \n",
    "    sjlabs = dfl.loc['sj']\n",
    "    iqlabs = dfl.loc['iq']\n",
    "\n",
    "    \n",
    "    sjlabs = sjlabs.as_matrix()\n",
    "    iqlabs = iqlabs.as_matrix()\n",
    "    \n",
    "    return sjfeats, iqfeats, sjlabs, iqlabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_data_test(data):\n",
    "    \n",
    "    df = data\n",
    "    \n",
    "    # fill missing values\n",
    "    df.fillna(method='ffill', inplace=True)\n",
    "    \n",
    "    df = df.drop(['week_start_date'],axis=1)\n",
    "  \n",
    "\n",
    "    # separate san juan and iquitos\n",
    "    sjfeats = df.loc['sj']\n",
    "    iqfeats = df.loc['iq']\n",
    "    \n",
    "    \n",
    "    return sjfeats, iqfeats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_features = pd.read_csv('dengue_features_test.csv',\n",
    "                             index_col=[0,1,2])\n",
    "\n",
    "sj_test, iq_test = preprocess_data_test(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sj_train, iq_train, sj_target, iq_target = preprocess_data(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#sjx_train, sjx_test, sjy_train, sjy_test = train_test_split(sj_train, sj_target, \n",
    "#                                                                    test_size=0.2, random_state=42)\n",
    "\n",
    "#iqx_train, iqx_test, iqy_train, iqy_test = train_test_split(iq_train, iq_target, \n",
    "#                                                                    test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def feature_boost(train_feats, train_labs, comp_feats):    \n",
    "    clf = GradientBoostingRegressor(random_state = 8001)\n",
    "\n",
    "    selector = clf.fit(train_feats, train_labs)\n",
    "    importances = selector.feature_importances_\n",
    "    fs = SelectFromModel(selector, prefit=True)\n",
    "    train = fs.transform(train_feats)\n",
    "    test = fs.transform(comp_feats)\n",
    "    \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/griffin/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:526: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-24543cc8961b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msj_train_feats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msj_test_feats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_boost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msj_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msj_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msj_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0miq_train_feats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miq_test_feats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_boost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miq_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miq_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miq_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-38-0a4f1035c628>\u001b[0m in \u001b[0;36mfeature_boost\u001b[0;34m(train_feats, train_labs, comp_feats)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSelectFromModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_feats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomp_feats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/griffin/anaconda3/lib/python3.6/site-packages/sklearn/feature_selection/base.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0minput\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0monly\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mselected\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \"\"\"\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_support\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/griffin/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    405\u001b[0m                              % (array.ndim, estimator_name))\n\u001b[1;32m    406\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m             \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/griffin/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m     56\u001b[0m             and not np.isfinite(X).all()):\n\u001b[1;32m     57\u001b[0m         raise ValueError(\"Input contains NaN, infinity\"\n\u001b[0;32m---> 58\u001b[0;31m                          \" or a value too large for %r.\" % X.dtype)\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "sj_train_feats, sj_test_feats = feature_boost(sj_train, sj_target, sj_test)\n",
    "iq_train_feats, iq_test_feats = feature_boost(iq_train, iq_target, iq_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def xgb_model(train_feats, train_labs):\n",
    "\n",
    "# Create an empty array for prediction\n",
    "    predictedResult = np.zeros(train_feats.shape[0])\n",
    "\n",
    "# Split dataset into k = 10 consecutive folds\n",
    "# Each fold is used once as a validation while the k - 1 remaining folds form the training set\n",
    "    kf = KFold(train_feats.shape[0], n_folds=5)\n",
    "\n",
    "    testPred = []\n",
    "\n",
    "    for trainIndex, testIndex in kf:\n",
    "        trainFold, testFold = train_feats[trainIndex], train_feats[testIndex]\n",
    "        trainFoldTarget, testFoldTarget = train_labs[trainIndex], train_labs[testIndex]\n",
    "    \n",
    "        xgbr = xgb.XGBRegressor(n_estimators = 100, # number of boosted trees\n",
    "                             learning_rate = 0.1, # step size shrinkage used in update to prevent overfitting\n",
    "                             max_depth = 9, # maximum depth of a tree\n",
    "                             min_child_weight = 5,   \n",
    "                             subsample = 0.8, # subsample ratio of the training set (Stochastic gradient boosting)\n",
    "                             colsample_bytree = 0.8) # subsample features\n",
    "    \n",
    "        xgbr.fit(trainFold, trainFoldTarget)\n",
    "        xgbpred =xgbr.predict(testFold)\n",
    "        #testPred.append(xgbr.predict(test_feats))\n",
    "        predictedResult[testIndex] = xgbpred\n",
    "    \n",
    "    \n",
    "        print(metrics.mean_absolute_error(testFoldTarget, xgbpred))\n",
    "    \n",
    "    return xgbr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26.0248900956\n",
      "42.1109017091\n",
      "31.3446045693\n",
      "23.8472454229\n",
      "27.1324818695\n"
     ]
    }
   ],
   "source": [
    "sj_xgbr = xgb_model(sj_train_feats, sj_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.3059001267\n",
      "6.70005340186\n",
      "8.7585333729\n",
      "6.02006647449\n",
      "10.2521702464\n",
      "6.91526018656\n",
      "6.02462487037\n",
      "7.47143287899\n",
      "10.7773930144\n",
      "7.63899595692\n"
     ]
    }
   ],
   "source": [
    "iq_xgbr = xgb_model(iq_train_feats, iq_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sj_pred = sj_xgbr.predict(sj_test_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iq_pred = iq_xgbr.predict(iq_test_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sj_pred = list(map(int, sj_pred))\n",
    "iq_pred = list(map(int, iq_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission = pd.read_csv(\"submission_format.csv\",\n",
    "                         index_col=[0, 1, 2])\n",
    "\n",
    "submission.total_cases = np.concatenate([sj_pred, iq_pred])\n",
    "submission.to_csv(\"submission_MLP.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
