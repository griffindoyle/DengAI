{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/griffin/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import time\n",
    "import datetime\n",
    "import math\n",
    "from sklearn import datasets\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.feature_selection import SelectFromModel, VarianceThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_features = pd.read_csv('dengue_features_train.csv',\n",
    "                             index_col=[0,1,2])\n",
    "train_labels = pd.read_csv('dengue_labels_train.csv',\n",
    "                          index_col=[0,1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42\n",
    "tf.set_random_seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_data(data, labels):\n",
    "    \n",
    "    df = data\n",
    "    \n",
    "    # fill missing values\n",
    "    df.fillna(method='ffill', inplace=True)\n",
    "    \n",
    "    df = df.drop(['week_start_date'],axis=1)\n",
    "\n",
    "    dfl = labels\n",
    "    \n",
    "    \n",
    "    # separate san juan and iquitos\n",
    "    sjfeats = df.loc['sj']\n",
    "    iqfeats = df.loc['iq']\n",
    "    \n",
    "    sjlabs = dfl.loc['sj']\n",
    "    iqlabs = dfl.loc['iq']\n",
    "\n",
    "    \n",
    "    sjlabs = sjlabs.as_matrix()\n",
    "    iqlabs = iqlabs.as_matrix()\n",
    "    \n",
    "    return sjfeats, iqfeats, sjlabs, iqlabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_data_test(data):\n",
    "    \n",
    "    df = data\n",
    "    \n",
    "    # fill missing values\n",
    "    df.fillna(method='ffill', inplace=True)\n",
    "    \n",
    "    df = df.drop(['week_start_date'],axis=1)\n",
    "  \n",
    "\n",
    "    # separate san juan and iquitos\n",
    "    sjfeats = df.loc['sj']\n",
    "    iqfeats = df.loc['iq']\n",
    "    \n",
    "    \n",
    "    return sjfeats, iqfeats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features = pd.read_csv('dengue_features_test.csv',\n",
    "                             index_col=[0,1,2])\n",
    "\n",
    "sj_test, iq_test = preprocess_data_test(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sj_train, iq_train, sj_target, iq_target = preprocess_data(train_features, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sjx_train, sjx_test, sjy_train, sjy_test = train_test_split(sj_train, sj_target, \n",
    "                                                                    test_size=0.2, random_state=42)\n",
    "\n",
    "iqx_train, iqx_test, iqy_train, iqy_test = train_test_split(iq_train, iq_target, \n",
    "                                                                    test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def feature_boost(train_feats, train_labs, test_feats, comp_feats):    \n",
    "    clf = GradientBoostingRegressor(random_state = 8001)\n",
    "\n",
    "    selector = clf.fit(train_feats, train_labs)\n",
    "    importances = selector.feature_importances_\n",
    "    fs = SelectFromModel(selector, prefit=True)\n",
    "    train = fs.transform(train_feats)\n",
    "    test = fs.transform(test_feats)\n",
    "    comp = fs.transform(comp_feats)\n",
    "    \n",
    "    return train, test, comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/griffin/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:526: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "sj_train_feats, sj_test_feats, sj_comp = feature_boost(sjx_train, sjy_train, sjx_test, sj_test)\n",
    "iq_train_feats, iq_test_feats, iq_comp = feature_boost(iqx_train, iqy_train, iqx_test, iq_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def xgb_model(train_feats, train_labs, test_feats):\n",
    "\n",
    "# Create an empty array for prediction\n",
    "    predictedResult = np.zeros(train_feats.shape[0])\n",
    "\n",
    "# Split dataset into k = 10 consecutive folds\n",
    "# Each fold is used once as a validation while the k - 1 remaining folds form the training set\n",
    "    kf = KFold(train_feats.shape[0], n_folds=10)\n",
    "\n",
    "    testPred = []\n",
    "\n",
    "    for trainIndex, testIndex in kf:\n",
    "        trainFold, testFold = train_feats[trainIndex], train_feats[testIndex]\n",
    "        trainFoldTarget, testFoldTarget = train_labs[trainIndex], train_labs[testIndex]\n",
    "    \n",
    "        xgbr = xgb.XGBRegressor(n_estimators = 560, # number of boosted trees\n",
    "                             learning_rate = 0.0202047, # step size shrinkage used in update to prevent overfitting\n",
    "                             max_depth = 5, # maximum depth of a tree\n",
    "                             subsample = 0.6815, # subsample ratio of the training set (Stochastic gradient boosting)\n",
    "                             colsample_bytree = 0.701) # subsample features\n",
    "    \n",
    "        xgbr.fit(trainFold, trainFoldTarget)\n",
    "        xgbpred =xgbr.predict(testFold)\n",
    "        testPred.append(xgbr.predict(test_feats))\n",
    "        predictedResult[testIndex] = xgbpred\n",
    "    \n",
    "    \n",
    "        print(metrics.mean_absolute_error(testFoldTarget, xgbpred))\n",
    "    \n",
    "    return xgbr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22.7433259201\n",
      "26.0321743393\n",
      "25.0134624577\n",
      "26.8701399485\n",
      "21.2800697072\n",
      "27.7215311305\n",
      "20.7993202909\n",
      "20.8004616737\n",
      "20.2175810015\n",
      "20.1293031581\n"
     ]
    }
   ],
   "source": [
    "sj_xgbr = xgb_model(sj_train_feats, sjy_train, sj_test_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.18418627977\n",
      "5.49578926961\n",
      "9.36237240121\n",
      "6.71961743846\n",
      "5.35679241305\n",
      "6.6936224699\n",
      "8.33327088123\n",
      "5.47649719221\n",
      "5.36567196759\n",
      "4.95160611228\n"
     ]
    }
   ],
   "source": [
    "iq_xgbr = xgb_model(iq_train_feats, iqy_train, iq_test_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sj_pred = sj_xgbr.predict(sj_comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iq_pred = iq_xgbr.predict(iq_comp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sj_pred = list(map(int, sj_pred))\n",
    "iq_pred = list(map(int, iq_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission = pd.read_csv(\"submission_format.csv\",\n",
    "                         index_col=[0, 1, 2])\n",
    "\n",
    "submission.total_cases = np.concatenate([sj_pred, iq_pred])\n",
    "submission.to_csv(\"submission_MLP.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
